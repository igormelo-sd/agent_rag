# agent.py 
import os
import logging
from typing import Dict, Any, List, Tuple

# Carregar vari√°veis do arquivo .env
from dotenv import load_dotenv
load_dotenv()

# Desabilitar LangSmith (opcional - remove warnings)
os.environ["LANGCHAIN_TRACING_V2"] = "false"
os.environ["LANGCHAIN_API_KEY"] = ""

# Imports corretos para a nova API
from langchain_openai import ChatOpenAI
from langchain.agents import create_react_agent, AgentExecutor
from langchain.tools import Tool
from langchain.prompts import PromptTemplate
from langchain import hub
from langchain.schema import HumanMessage, AIMessage

# LangGraph imports para mem√≥ria
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph
from typing_extensions import TypedDict

# Import correto considerando que estamos na pasta rag
try:
    from rag_system import RagSystem
    RAG_AVAILABLE = True
except ImportError as e:
    RAG_AVAILABLE = False
    print(f"‚ö†Ô∏è Aviso: RagSystem n√£o dispon√≠vel: {e}")

# Verificar se ChromaDB est√° dispon√≠vel
try:
    import chromadb
    CHROMADB_AVAILABLE = True
except ImportError:
    CHROMADB_AVAILABLE = False
    print("‚ö†Ô∏è Aviso: ChromaDB n√£o dispon√≠vel")

# Configurar logging
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="langsmith")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# Estado para o LangGraph
class ConversationState(TypedDict):
    messages: List[Dict[str, str]]
    last_user_message: str
    last_ai_message: str


class RAGAgentReact:
    """
    Agente RAG aprimorado com tratamento robusto de erros e fallback.
    CORRE√á√ÉO: Simplifica√ß√£o do prompt e controle de itera√ß√µes para evitar loops.
    Atualizado com LangGraph Memory System.
    """
    
    def __init__(self, openai_api_key: str = None):
        """
        Inicializa o agente RAG com configura√ß√µes aprimoradas e tratamento de erro.
        """
        # Carregar do .env se n√£o fornecida
        if openai_api_key:
            os.environ["OPENAI_API_KEY"] = openai_api_key
        else:
            # Verificar se foi carregada do .env
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError(
                    "OPENAI_API_KEY n√£o encontrada. Verifique se:\n"
                    "1. O arquivo .env existe na raiz do projeto\n"
                    "2. Cont√©m: OPENAI_API_KEY=sk-seu-token-aqui\n"
                    "3. O python-dotenv est√° instalado: pip install python-dotenv"
                )
            print(f"‚úÖ API Key carregada do .env: {api_key[:10]}...")
        
        # Inicializa√ß√£o segura do sistema RAG
        self.rag_available = False
        self.rag_status = "not_initialized"
        
        if RAG_AVAILABLE and CHROMADB_AVAILABLE:
            try:
                print("üîÑ Inicializando sistema RAG...")
                self.rag = RagSystem()
                
                # Testar a conex√£o do sistema RAG
                system_info = self.rag.get_system_info()
                
                if system_info.get('rag_available', False):
                    self.rag_available = True
                    self.rag_status = "active"
                    print(f"‚úÖ Sistema RAG inicializado: {system_info.get('rag_status', 'Status desconhecido')}")
                else:
                    self.rag_status = f"initialization_failed: {system_info.get('rag_status', 'Falha desconhecida')}"
                    print(f"‚ö†Ô∏è Sistema RAG com problemas: {system_info.get('rag_status', 'Falha desconhecida')}")
                    
            except Exception as e:
                logger.error(f"Erro ao inicializar RAG: {e}")
                self.rag_status = f"error: {str(e)}"
                print(f"‚ùå Erro na inicializa√ß√£o do RAG: {e}")
        elif not CHROMADB_AVAILABLE:
            self.rag_status = "chromadb_not_available"
            print("‚ùå ChromaDB n√£o dispon√≠vel - instale com: pip install chromadb")
        else:
            self.rag_status = "rag_system_not_available"
            print("‚ùå RagSystem n√£o dispon√≠vel")
        
        # Configura√ß√£o do LLM com par√¢metros otimizados
        self.llm = ChatOpenAI(
            temperature=0.3,  # Reduzido para mais consist√™ncia
            model="gpt-4o",
            max_tokens=8000,   # Reduzido para evitar timeouts
            top_p=0.9,
        )
        
        # MUDAN√áA PRINCIPAL: Substituir ConversationBufferMemory por LangGraph Memory
        self.memory_saver = MemorySaver()
        self.thread_id = "main_conversation"  # ID √∫nico para a thread de conversa√ß√£o
        
        # Inicializar estado da conversa√ß√£o
        self.conversation_state: ConversationState = {
            "messages": [],
            "last_user_message": "",
            "last_ai_message": ""
        }
        
        # Definir ferramentas simplificadas
        self.tools = self._create_simplified_tools()
        
        # Criar prompt simplificado
        self.prompt = self._create_simplified_prompt()
        
        # Criar agente usando create_react_agent
        self.agent = create_react_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=self.prompt
        )
        
        # CORRE√á√ÉO PRINCIPAL: Configura√ß√µes mais restritivas para evitar loops
        self.agent_executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            verbose=True,
            handle_parsing_errors=True,
            max_iterations=3,        # REDUZIDO de 5 para 3
            max_execution_time=60,   # REDUZIDO de 120 para 60 segundos
            return_intermediate_steps=False,  # Desabilitado para simplicidade
            early_stopping_method="generate"  # Para quando conseguir uma resposta
        )
        
        logger.info(f"Agente RAG inicializado - Status RAG: {self.rag_status}")
    
    def _add_to_memory(self, user_message: str, ai_message: str):
        """Adiciona mensagens √† mem√≥ria usando LangGraph."""
        try:
            # Atualizar estado da conversa√ß√£o
            self.conversation_state["messages"].append({
                "role": "user",
                "content": user_message,
                "timestamp": str(int(os.times().elapsed))
            })
            self.conversation_state["messages"].append({
                "role": "assistant", 
                "content": ai_message,
                "timestamp": str(int(os.times().elapsed))
            })
            
            self.conversation_state["last_user_message"] = user_message
            self.conversation_state["last_ai_message"] = ai_message
            
            # Salvar no MemorySaver
            self.memory_saver.put(
                config={"configurable": {"thread_id": self.thread_id}},
                checkpoint={
                    "state": self.conversation_state,
                    "metadata": {"step": len(self.conversation_state["messages"]) // 2}
                }
            )
            
            logger.info(f"Mensagens adicionadas √† mem√≥ria. Total: {len(self.conversation_state['messages'])}")
            
        except Exception as e:
            logger.error(f"Erro ao salvar na mem√≥ria: {e}")
    
    def _get_chat_history(self) -> List[Dict[str, str]]:
        """Recupera o hist√≥rico de chat da mem√≥ria."""
        try:
            # Tentar recuperar do MemorySaver
            checkpoint = self.memory_saver.get(
                config={"configurable": {"thread_id": self.thread_id}}
            )
            
            if checkpoint and "state" in checkpoint:
                return checkpoint["state"].get("messages", [])
            else:
                return self.conversation_state["messages"]
                
        except Exception as e:
            logger.error(f"Erro ao recuperar hist√≥rico: {e}")
            return self.conversation_state["messages"]
    
    def _format_chat_history_for_prompt(self) -> str:
        """Formata o hist√≥rico para incluir no prompt."""
        history = self._get_chat_history()
        if not history:
            return ""
        
        # Pegar apenas as √∫ltimas 6 mensagens para evitar prompts muito longos
        recent_history = history[-6:] if len(history) > 6 else history
        
        formatted = []
        for msg in recent_history:
            role = "Human" if msg["role"] == "user" else "Assistant"
            formatted.append(f"{role}: {msg['content'][:200]}...")  # Truncar para evitar prompts longos
        
        return "\n".join(formatted)
    
    def _create_simplified_tools(self) -> List[Tool]:
        """Cria ferramentas simplificadas para evitar loops."""
        tools = []
        
        if self.rag_available:
            # CORRE√á√ÉO: Apenas uma ferramenta principal para evitar confus√£o do agente
            tools.append(
                Tool(
                    name="consultar_base_conhecimento",
                    func=self._consultar_rag_direto,
                    description="""FERRAMENTA PRINCIPAL: Consulta a base de conhecimento sobre economia de S√£o Paulo.
                    Use esta ferramenta para responder perguntas sobre:
                    - Ind√∫stria (automotiva, t√™xtil, farmac√™utica, metal√∫rgica, etc.)
                    - Economia do Estado de S√£o Paulo
                    - Dados estat√≠sticos e indicadores
                    - Mapa da Ind√∫stria Paulista
                    - Balan√ßa Comercial
                    - Agropecu√°ria e outros setores
                    
                    Input: A pergunta exata do usu√°rio
                    Output: Resposta completa baseada na base de conhecimento"""
                )
            )
        else:
            tools.append(
                Tool(
                    name="resposta_geral",
                    func=self._resposta_conhecimento_geral,
                    description="""Use esta ferramenta quando o sistema RAG n√£o estiver dispon√≠vel.
                    Fornece informa√ß√µes gerais sobre economia de S√£o Paulo.
                    
                    Input: Pergunta do usu√°rio
                    Output: Resposta baseada em conhecimento geral"""
                )
            )
        
        return tools
    
    def _create_simplified_prompt(self) -> PromptTemplate:
        """Cria um prompt simplificado que evita loops infinitos."""
        
        # CORRE√á√ÉO: Definir template base primeiro, depois personalizar
        base_template = """Voc√™ √© um ESPECIALISTA em economia do Estado de S√£o Paulo.

IMPORTANTE: Para sauda√ß√µes simples (ol√°, oi, bom dia, etc.) responda diretamente SEM usar ferramentas.

Para outras perguntas sobre economia paulista, use as ferramentas dispon√≠veis.

HIST√ìRICO DA CONVERSA:
{chat_history}

Ferramentas dispon√≠veis:
{tools}

Use o seguinte formato:

Question: {input}
Thought: an√°lise da pergunta
Action: escolha uma ferramenta de [{tool_names}]
Action Input: entrada para a ferramenta
Observation: resultado da ferramenta
Thought: an√°lise final
Final Answer: resposta completa e estruturada

{agent_scratchpad}"""
        
        if self.rag_available:
            # Template espec√≠fico para quando RAG est√° dispon√≠vel
            template = """Voc√™ √© um ESPECIALISTA em economia do Estado de S√£o Paulo, com foco espec√≠fico em:
- Ind√∫stria Automotiva
- Ind√∫stria T√™xtil e de Confec√ß√µes  
- Ind√∫stria Farmac√™utica
- M√°quinas e Equipamentos
- Mapa da Ind√∫stria Paulista
- Ind√∫stria Metal√∫rgica
- Agropecu√°ria e Transi√ß√£o Energ√©tica
- Balan√ßa Comercial Paulista
- Biocombust√≠veis

INSTRU√á√ïES PARA RESPOSTAS DETALHADAS:

1. Use a ferramenta dispon√≠vel para coletar informa√ß√µes abrangentes
2. Estruture suas respostas com numera√ß√£o, subt√≥picos e formata√ß√£o clara
3. Inclua dados espec√≠ficos, estat√≠sticas e exemplos sempre que dispon√≠vel
4. Desenvolva cada ponto com explica√ß√µes detalhadas
5. Use linguagem t√©cnica apropriada mas acess√≠vel

FORMATO OBRIGAT√ìRIO para Final Answer:
- Use numera√ß√£o (1., 2., 3., etc.) para pontos principais
- Use subt√≥picos com **negrito** para destacar aspectos importantes
- Inclua dados quantitativos quando dispon√≠vel
- Desenvolva cada ponto com pelo menos 2-3 frases explicativas

EXCE√á√ïES para respostas diretas (SEM usar ferramentas):
- **Sauda√ß√µes**: "Ol√°", "Oi", "Bom dia", "Boa tarde", "Boa noite", "Tudo bem?", etc.
- **Confirma√ß√µes**: "Ok", "Entendi", "Certo", "Sim", "N√£o"
- **Perguntas sobre funcionamento**: "Como voc√™ funciona?", "O que voc√™ pode fazer?"
- **Despedidas**: "Tchau", "At√© logo", "Obrigado"

Para essas exce√ß√µes, responda diretamente de forma amig√°vel.

HIST√ìRICO DA CONVERSA:
{chat_history}

Ferramentas dispon√≠veis:
{tools}

Use o seguinte formato:

Question: {input}
Thought: an√°lise da pergunta e estrat√©gia
Action: escolha uma ferramenta de [{tool_names}]
Action Input: entrada espec√≠fica para a ferramenta
Observation: resultado da ferramenta
Thought: an√°lise final de todas as informa√ß√µes
Final Answer: resposta DETALHADA, ESTRUTURADA e COMPLETA

{agent_scratchpad}"""
        else:
            # Template para quando RAG n√£o est√° dispon√≠vel
            template = """Voc√™ √© um assistente especializado em economia do Estado de S√£o Paulo.

‚ö†Ô∏è AVISO: Sistema de base de conhecimento n√£o dispon√≠vel. Respostas baseadas em conhecimento geral.

EXCE√á√ïES para respostas diretas (SEM usar ferramentas):
- **Sauda√ß√µes**: "Ol√°", "Oi", "Bom dia", etc.
- **Confirma√ß√µes**: "Ok", "Entendi", "Certo"
- **Despedidas**: "Tchau", "At√© logo"

Para essas exce√ß√µes, responda diretamente.

HIST√ìRICO DA CONVERSA:
{chat_history}

Ferramentas dispon√≠veis:
{tools}

Use o seguinte formato:

Question: {input}
Thought: an√°lise da pergunta
Action: escolha uma ferramenta de [{tool_names}]
Action Input: entrada para a ferramenta
Observation: resultado da ferramenta
Thought: an√°lise final
Final Answer: resposta com base no conhecimento geral dispon√≠vel

{agent_scratchpad}"""
        
        return PromptTemplate.from_template(template)
    
    def _consultar_rag_direto(self, query: str) -> str:
        """
        CORRE√á√ÉO: Consulta direta e simplificada do RAG.
        """
        try:
            if not self.rag_available:
                return f"‚ùå Sistema RAG n√£o dispon√≠vel. Status: {self.rag_status}"
            
            logger.info(f"Consulta RAG: {query}")
            
            # Usar o m√©todo correto baseado no RagSystem fornecido
            resultado = self.rag.query_rag_system(query)
            
            if 'error' in resultado:
                logger.error(f"Erro no RAG: {resultado['error']}")
                return f"‚ö†Ô∏è Erro no sistema: {resultado['error']}"
            
            response = resultado.get("response", "")
            
            if not response or len(response.strip()) < 10:
                return "‚ö†Ô∏è Resposta muito curta ou vazia. Verifique se h√° documentos na base de dados."
            
            # Adicionar metadados mais detalhados
            retrieved_docs = len(resultado.get('retrieved_documents', []))
            reranked_docs = len(resultado.get('reranked_documents', []))
            confidence = resultado.get('confidence_scores', 'N/A')
            
            metadata_info = f"\n\nüìä _Consulta baseada em {retrieved_docs} documento(s) recuperado(s)"
            if reranked_docs > 0:
                metadata_info += f", {reranked_docs} reranqueado(s)"
            if confidence != 'N/A':
                metadata_info += f" (confian√ßa: {confidence})"
            metadata_info += "._"
            
            return response + metadata_info
            
        except AttributeError as e:
            logger.error(f"M√©todo n√£o encontrado no RAG: {e}")
            return f"‚ùå Erro: M√©todo de consulta n√£o encontrado no sistema RAG: {str(e)}"
        except Exception as e:
            logger.error(f"Erro na consulta RAG: {e}")
            return f"‚ùå Erro na consulta: {str(e)}"
    
    def _resposta_conhecimento_geral(self, query: str) -> str:
        """Resposta quando RAG n√£o est√° dispon√≠vel."""
        return f"""‚ö†Ô∏è **Sistema de base de conhecimento indispon√≠vel**

Pergunta: "{query}"

**Resposta baseada em conhecimento geral:**

S√£o Paulo √© o principal centro econ√¥mico do Brasil, respons√°vel por cerca de 1/3 do PIB nacional. O estado se destaca em diversos setores:

**Principais Setores:**
- **Ind√∫stria Automotiva**: Concentrada no ABC paulista e regi√£o de Campinas
- **Ind√∫stria Farmac√™utica**: Forte presen√ßa na regi√£o metropolitana
- **T√™xtil e Confec√ß√µes**: Setor tradicional do estado
- **M√°quinas e Equipamentos**: Distribu√≠do por v√°rias regi√µes
- **Agropecu√°ria**: Interior do estado, forte em cana-de-a√ß√∫car, caf√©, laranja

**‚ö†Ô∏è IMPORTANTE**: Resposta baseada em conhecimento geral. Para informa√ß√µes precisas, consulte:
- FIESP (Federa√ß√£o das Ind√∫strias do Estado de S√£o Paulo)
- Funda√ß√£o SEADE
- IBGE

Status do sistema RAG: {self.rag_status}"""
    
    def _is_simple_greeting(self, text: str) -> bool:
        """Verifica se √© uma sauda√ß√£o simples que n√£o precisa de ferramentas."""
        greetings = [
            "ol√°", "oi", "oi√™", "ola", "bom dia", "boa tarde", "boa noite",
            "como vai", "tudo bem", "e a√≠", "salve", "al√¥", "hello", "hi"
        ]
        text_lower = text.lower().strip()
        return any(greeting in text_lower for greeting in greetings) and len(text_lower) < 20
    
    def consultar(self, pergunta: str) -> str:
        """
        CORRE√á√ÉO PRINCIPAL: Consulta simplificada que evita loops.
        """
        if not pergunta.strip():
            return "Por favor, forne√ßa uma pergunta v√°lida."
        
        try:
            logger.info(f"Processando pergunta: {pergunta}")
            
            # CORRE√á√ÉO: Verificar se √© sauda√ß√£o simples
            if self._is_simple_greeting(pergunta):
                resposta = """üëã **Ol√°! Seja bem-vindo!**

Sou um assistente especializado em economia do Estado de S√£o Paulo. Posso ajud√°-lo com informa√ß√µes sobre:

üè≠ **Setores Industriais:**
- Ind√∫stria Automotiva
- Ind√∫stria T√™xtil e Confec√ß√µes
- Ind√∫stria Farmac√™utica
- M√°quinas e Equipamentos
- Ind√∫stria Metal√∫rgica

üìä **Dados Econ√¥micos:**
- Balan√ßa Comercial Paulista
- Mapa da Ind√∫stria Paulista
- Agropecu√°ria e Transi√ß√£o Energ√©tica
- Biocombust√≠veis

üí¨ **Como posso ajudar?**
Fa√ßa sua pergunta sobre qualquer aspecto da economia paulista!"""
                
                # Adicionar √† mem√≥ria
                self._add_to_memory(pergunta, resposta)
                return resposta
            
            # Preparar input com hist√≥rico de chat
            chat_history = self._format_chat_history_for_prompt()
            input_with_history = {
                "input": pergunta,
                "chat_history": chat_history
            }
            
            # Executar com timeout mais restritivo
            resultado = self.agent_executor.invoke(
                input_with_history,
                config={"max_execution_time": 45}  # 45 segundos m√°ximo
            )
            
            resposta = resultado.get("output", "N√£o foi poss√≠vel obter uma resposta.")
            
            # CORRE√á√ÉO: Verificar se a resposta √© v√°lida
            if "Agent stopped due to iteration limit" in resposta:
                # Fallback direto quando h√° problema de itera√ß√£o
                if self.rag_available:
                    logger.warning("Fallback: usando consulta RAG direta")
                    resposta = self._consultar_rag_direto(pergunta)
                else:
                    logger.warning("Fallback: usando conhecimento geral")
                    resposta = self._resposta_conhecimento_geral(pergunta)
            
            # Adicionar √† mem√≥ria
            self._add_to_memory(pergunta, resposta)
            
            return resposta
            
        except Exception as e:
            logger.error(f"Erro ao consultar agente: {e}")
            
            # CORRE√á√ÉO: Fallback robusto em caso de erro
            if self.rag_available:
                try:
                    logger.info("Tentando fallback com RAG direto")
                    resposta = self._consultar_rag_direto(pergunta)
                    self._add_to_memory(pergunta, resposta)
                    return resposta
                except:
                    pass
            
            resposta_erro = f"""‚ùå **Erro no processamento**

Ocorreu um erro ao processar sua pergunta: {str(e)}

**Poss√≠veis solu√ß√µes:**
1. Tente reformular a pergunta
2. Verifique se √© uma pergunta sobre economia de S√£o Paulo
3. Se o problema persistir, reinicie o sistema

Status do RAG: {self.rag_status}"""
            
            self._add_to_memory(pergunta, resposta_erro)
            return resposta_erro
    
    def get_system_info(self) -> Dict[str, Any]:
        """Retorna informa√ß√µes sobre o status do sistema."""
        info = {
            "rag_available": self.rag_available,
            "rag_status": self.rag_status,
            "tools_count": len(self.tools),
            "agent_ready": hasattr(self, 'agent_executor'),
            "max_iterations": 3,  # Atualizado
            "max_execution_time": 60,  # Atualizado
            "memory_system": "LangGraph MemorySaver",
            "messages_count": len(self._get_chat_history()),
            "chromadb_available": CHROMADB_AVAILABLE
        }
        
        if self.rag_available and hasattr(self, 'rag'):
            try:
                rag_status = self.rag.get_system_info()
                info.update({
                    "rag_detailed_status": rag_status,
                    "reranking_enabled": rag_status.get('reranking_enabled', False),
                    "llm_model": rag_status.get('llm_model', 'unknown')
                })
            except Exception as e:
                info["rag_error"] = str(e)
        
        return info
    
    def __call__(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """
        CORRE√á√ÉO: M√©todo para compatibilidade com Streamlit simplificado.
        Atualizado para usar LangGraph memory.
        """
        question = inputs.get("question", "")
        
        if not question:
            return {"chat_history": []}
        
        # Obter resposta do agente
        response = self.consultar(question)
        
        # Converter mensagens do formato LangGraph para o formato LangChain
        # para compatibilidade com Streamlit
        langgraph_messages = self._get_chat_history()
        langchain_messages = []
        
        for msg in langgraph_messages:
            if msg["role"] == "user":
                langchain_messages.append(HumanMessage(content=msg["content"]))
            else:
                langchain_messages.append(AIMessage(content=msg["content"]))
        
        # Retornar no formato esperado pelo Streamlit
        return {
            "chat_history": langchain_messages,
            "output": response  # Adicionar output direto para compatibilidade
        }
    
    def clear_memory(self):
        """Limpa a mem√≥ria da conversa√ß√£o."""
        try:
            self.conversation_state = {
                "messages": [],
                "last_user_message": "",
                "last_ai_message": ""
            }
            logger.info("Mem√≥ria limpa com sucesso")
        except Exception as e:
            logger.error(f"Erro ao limpar mem√≥ria: {e}")
    
    def run_interactive(self):
        """Executa o loop interativo."""
        print("=== Agente RAG Corrigido - Sistema de Consulta ===")
        print("Especialista em economia do Estado de S√£o Paulo")
        print("Agora com LangGraph Memory System")
        
        # Mostrar status do sistema
        system_info = self.get_system_info()
        print(f"\nüìä **Status do Sistema:**")
        print(f"RAG dispon√≠vel: {'‚úÖ Sim' if system_info['rag_available'] else '‚ùå N√£o'}")
        print(f"Status: {system_info['rag_status']}")
        print(f"ChromaDB dispon√≠vel: {'‚úÖ Sim' if system_info['chromadb_available'] else '‚ùå N√£o'}")
        print(f"M√°x itera√ß√µes: {system_info['max_iterations']}")
        print(f"Timeout: {system_info['max_execution_time']}s")
        print(f"Sistema de mem√≥ria: {system_info['memory_system']}")
        print(f"Mensagens na mem√≥ria: {system_info['messages_count']}")
        
        # Mostrar detalhes do RAG se dispon√≠vel
        if system_info.get('rag_detailed_status'):
            rag_details = system_info['rag_detailed_status']
            print(f"Reranking habilitado: {'‚úÖ Sim' if rag_details.get('reranking_enabled') else '‚ùå N√£o'}")
            print(f"Modelo LLM: {rag_details.get('llm_model', 'N/A')}")
        
        print(f"\nDigite 'sair' para encerrar, 'limpar' para limpar hist√≥rico, 'status' para ver informa√ß√µes\n")
        
        while True:
            try:
                user_input = input("> ").strip()
                
                if user_input.lower() in ["sair", "exit", "quit"]:
                    print("Encerrando. At√© logo!")
                    break
                
                if user_input.lower() in ["limpar", "clear"]:
                    self.clear_memory()
                    print("üßπ Hist√≥rico limpo!")
                    continue
                
                if user_input.lower() in ["status", "info"]:
                    info = self.get_system_info()
                    print("\nüìä **Status Atual:**")
                    for key, value in info.items():
                        if key != 'rag_detailed_status':
                            print(f"{key}: {value}")
                    print()
                    continue
                
                if not user_input:
                    continue
                
                print(f"\nüîç Processando...")
                resposta = self.consultar(user_input)
                
                print(f"\n{'='*60}")
                print("üìä RESPOSTA:")
                print(f"{'='*60}")
                print(f"{resposta}")
                print(f"{'='*60}\n")
                
            except KeyboardInterrupt:
                print("\nEncerrando. At√© logo!")
                break
            except Exception as e:
                logger.error(f"Erro no loop: {e}")
                print(f"Erro: {e}\n")


def create_rag_agent():
    """
    CORRE√á√ÉO: Fun√ß√£o para criar o agente RAG corrigido.
    """
    try:
        os.environ["ANONYMIZED_TELEMETRY"] = "False"
        
        print("Inicializando agente RAG com LangGraph...")
        agent = RAGAgentReact()
        
        system_info = agent.get_system_info()
        if system_info['rag_available']:
            print("‚úÖ Agente RAG completo inicializado!")
        else:
            print(f"‚ö†Ô∏è Agente em modo limitado - Status: {system_info['rag_status']}")
        
        return agent
        
    except Exception as e:
        print(f"‚ùå Erro ao inicializar: {e}")
        raise


if __name__ == "__main__":
    try:
        os.environ["ANONYMIZED_TELEMETRY"] = "False"
        agent = RAGAgentReact()
        agent.run_interactive()
        
    except ValueError as e:
        print(f"Erro de configura√ß√£o: {e}")
    except Exception as e:
        print(f"Erro: {e}")